adaptive_embedding_dim: 8
batch_size: 64
dataset: PEMS04
debug: True
dim_embed_feature: 120
early_stop: True
early_stop_patience: 15
embed_dim: 6
epochs: 120
flow_dim: 1
gpu_id: 0
grad_norm: False
holiday_dim: 1
holiday_embedding_dim: 2
hop_dim: 1
in_steps: 12
input_dim: 5
input_embedding_dim: 80
log_dir: ./exps/logs/
log_step: 20
loss_func: mae
lr_decay: True
lr_decay_rate: 0.2
lr_decay_step: 80,100
lr_init: 0.006
mae_thresh: None
mape_thresh: 0.0
max_grad_norm: 5
mode: Train
model: MGSTGNN
normalizer: std
num_layers: 3
num_nodes: 307
out_steps: 12
output_dim: 1
period_dim: 1
periods: [288]
periods_embedding_dim: [24]
plot: False
random: True
real_value: True
rnn_units: 64
seed: 10
spatial_embedding_dim: 0
test_ratio: 0.2
val_ratio: 0.2
weather_dim: 0
weekend_dim: 1
weekend_embedding_dim: 6
seed: tensor([389])
*****************Model Parameter*****************
encoder.node_emb torch.Size([307, 0]) True
encoder.adaptive_embedding torch.Size([12, 307, 8]) True
encoder.input_proj.weight torch.Size([80, 5]) True
encoder.input_proj.bias torch.Size([80]) True
encoder.periods_embedding.0.weight torch.Size([288, 24]) True
encoder.weekend_embedding.weight torch.Size([2, 6]) True
encoder.holiday_embedding.weight torch.Size([2, 2]) True
encoder.output_proj.weight torch.Size([12, 1440]) True
encoder.output_proj.bias torch.Size([12]) True
encoder.skip.weight torch.Size([120, 5]) True
encoder.skip.bias torch.Size([120]) True
encoder.ln.weight torch.Size([120]) True
encoder.ln.bias torch.Size([120]) True
mgstgnn.encoder.node_embeddings torch.Size([307, 6]) True
mgstgnn.encoder.time_embeddings torch.Size([12, 6]) True
mgstgnn.encoder.gru0.gate_r.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.gru0.gate_z.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.gru0.update.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_r.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_z.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.update.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_r.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_z.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.update.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.gats.0.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.0.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.0.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.0.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.1.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.1.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.1.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.1.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.2.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.2.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.2.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.2.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.3.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.3.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.3.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.3.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.4.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.4.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.4.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.4.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.5.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.5.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.5.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.5.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.6.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.6.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.6.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.6.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.7.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.7.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.7.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.7.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.8.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.8.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.8.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.8.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.9.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.9.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.9.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.9.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.10.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.10.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.10.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.10.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.11.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.11.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.11.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.11.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.norms.0.weight torch.Size([64]) True
mgstgnn.encoder.norms.0.bias torch.Size([64]) True
mgstgnn.encoder.norms.1.weight torch.Size([64]) True
mgstgnn.encoder.norms.1.bias torch.Size([64]) True
mgstgnn.encoder.norms.2.weight torch.Size([64]) True
mgstgnn.encoder.norms.2.bias torch.Size([64]) True
mgstgnn.encoder.norms.3.weight torch.Size([64]) True
mgstgnn.encoder.norms.3.bias torch.Size([64]) True
mgstgnn.encoder.norms.4.weight torch.Size([64]) True
mgstgnn.encoder.norms.4.bias torch.Size([64]) True
mgstgnn.encoder.norms.5.weight torch.Size([64]) True
mgstgnn.encoder.norms.5.bias torch.Size([64]) True
mgstgnn.encoder.norms.6.weight torch.Size([64]) True
mgstgnn.encoder.norms.6.bias torch.Size([64]) True
mgstgnn.encoder.norms.7.weight torch.Size([64]) True
mgstgnn.encoder.norms.7.bias torch.Size([64]) True
mgstgnn.encoder.norms.8.weight torch.Size([64]) True
mgstgnn.encoder.norms.8.bias torch.Size([64]) True
mgstgnn.encoder.norms.9.weight torch.Size([64]) True
mgstgnn.encoder.norms.9.bias torch.Size([64]) True
mgstgnn.encoder.norms.10.weight torch.Size([64]) True
mgstgnn.encoder.norms.10.bias torch.Size([64]) True
mgstgnn.encoder.norms.11.weight torch.Size([64]) True
mgstgnn.encoder.norms.11.bias torch.Size([64]) True
mgstgnn.norm.weight torch.Size([64]) True
mgstgnn.norm.bias torch.Size([64]) True
mgstgnn.end_conv.weight torch.Size([12, 2, 1, 64]) True
mgstgnn.end_conv.bias torch.Size([12]) True
Total params num: 2862414
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 307]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 289281
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 307]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 289281
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 12]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 138241
*****************Finish Parameter****************
(16992, 307, 5)
Train:  (10173, 12, 307, 5) (10173, 12, 307, 1)
Val:  (3375, 12, 307, 5) (3375, 12, 307, 1)
Test:  (3375, 12, 307, 5) (3375, 12, 307, 1)
Applying learning rate decay.
2023-11-06 11:52: Experiment log path in: /mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106115215
2023-11-06 11:52: Argument: Namespace(dataset='PEMS04', mode='Train', debug=True, model='MGSTGNN', gpu_id=0, val_ratio=0.2, test_ratio=0.2, in_steps=12, out_steps=12, num_nodes=307, normalizer='std', input_dim=5, flow_dim=1, period_dim=1, weekend_dim=1, holiday_dim=1, hop_dim=1, weather_dim=0, dim_embed_feature=120, input_embedding_dim=80, periods_embedding_dim=[24], weekend_embedding_dim=6, holiday_embedding_dim=2, spatial_embedding_dim=0, adaptive_embedding_dim=8, output_dim=1, embed_dim=6, rnn_units=64, num_layers=3, periods=[288], loss_func='mae', seed=tensor([389]), random=True, batch_size=64, epochs=120, lr_init=0.006, lr_decay=True, lr_decay_rate=0.2, lr_decay_step='80,100', early_stop=True, early_stop_patience=15, grad_norm=False, max_grad_norm=5, real_value=True, mae_thresh=None, mape_thresh=0.0, log_dir='/mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106115215', log_step=20, plot=False, device=device(type='cuda', index=0))
2023-11-06 11:52: adaptive_embedding_dim: 8
2023-11-06 11:52: batch_size: 64
2023-11-06 11:52: dataset: PEMS04
2023-11-06 11:52: debug: True
2023-11-06 11:52: device: cuda:0
2023-11-06 11:52: dim_embed_feature: 120
2023-11-06 11:52: early_stop: True
2023-11-06 11:52: early_stop_patience: 15
2023-11-06 11:52: embed_dim: 6
2023-11-06 11:52: epochs: 120
2023-11-06 11:52: flow_dim: 1
2023-11-06 11:52: gpu_id: 0
2023-11-06 11:52: grad_norm: False
2023-11-06 11:52: holiday_dim: 1
2023-11-06 11:52: holiday_embedding_dim: 2
2023-11-06 11:52: hop_dim: 1
2023-11-06 11:52: in_steps: 12
2023-11-06 11:52: input_dim: 5
2023-11-06 11:52: input_embedding_dim: 80
2023-11-06 11:52: log_dir: /mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106115215
2023-11-06 11:52: log_step: 20
2023-11-06 11:52: loss_func: mae
2023-11-06 11:52: lr_decay: True
2023-11-06 11:52: lr_decay_rate: 0.2
2023-11-06 11:52: lr_decay_step: 80,100
2023-11-06 11:52: lr_init: 0.006
2023-11-06 11:52: mae_thresh: None
2023-11-06 11:52: mape_thresh: 0.0
2023-11-06 11:52: max_grad_norm: 5
2023-11-06 11:52: mode: Train
2023-11-06 11:52: model: MGSTGNN
2023-11-06 11:52: normalizer: std
2023-11-06 11:52: num_layers: 3
2023-11-06 11:52: num_nodes: 307
2023-11-06 11:52: out_steps: 12
2023-11-06 11:52: output_dim: 1
2023-11-06 11:52: period_dim: 1
2023-11-06 11:52: periods: [288]
2023-11-06 11:52: periods_embedding_dim: [24]
2023-11-06 11:52: plot: False
2023-11-06 11:52: random: True
2023-11-06 11:52: real_value: True
2023-11-06 11:52: rnn_units: 64
2023-11-06 11:52: seed: tensor([389])
2023-11-06 11:52: spatial_embedding_dim: 0
2023-11-06 11:52: test_ratio: 0.2
2023-11-06 11:52: val_ratio: 0.2
2023-11-06 11:52: weather_dim: 0
2023-11-06 11:52: weekend_dim: 1
2023-11-06 11:52: weekend_embedding_dim: 6
2023-11-06 11:52: Train Epoch 1: 0/158 Generator Loss: 188.802002 Pred Discriminator Loss: 0.886458 spatial Discriminator Loss: 0.756691 temporal Discriminator Loss: 1.619418
2023-11-06 11:52: Train Epoch 1: 20/158 Generator Loss: 193.237381 Pred Discriminator Loss: 0.518359 spatial Discriminator Loss: 0.639320 temporal Discriminator Loss: 0.678220
2023-11-06 11:52: Train Epoch 1: 40/158 Generator Loss: 175.586151 Pred Discriminator Loss: 0.498975 spatial Discriminator Loss: 0.560486 temporal Discriminator Loss: 0.511125
2023-11-06 11:52: Train Epoch 1: 60/158 Generator Loss: 147.503555 Pred Discriminator Loss: 0.486440 spatial Discriminator Loss: 0.441560 temporal Discriminator Loss: 0.320200
2023-11-06 11:52: Train Epoch 1: 80/158 Generator Loss: 134.910614 Pred Discriminator Loss: 0.491929 spatial Discriminator Loss: 0.385209 temporal Discriminator Loss: 0.141862
2023-11-06 11:53: Train Epoch 1: 100/158 Generator Loss: 97.293678 Pred Discriminator Loss: 0.528181 spatial Discriminator Loss: 0.543539 temporal Discriminator Loss: 0.430191
2023-11-06 11:53: Train Epoch 1: 120/158 Generator Loss: 75.576828 Pred Discriminator Loss: 0.561898 spatial Discriminator Loss: 0.501460 temporal Discriminator Loss: 0.548316
2023-11-06 11:53: Train Epoch 1: 140/158 Generator Loss: 51.406578 Pred Discriminator Loss: 0.549281 spatial Discriminator Loss: 0.512135 temporal Discriminator Loss: 0.841486
2023-11-06 11:53: **********Train Epoch 1: Averaged Generator Loss: 126.544255, Averaged Pred Discriminator Loss: 0.539989, Averaged spatial Discriminator Loss: 0.538609, Averaged temporal Discriminator Loss: 0.559330
2023-11-06 11:53: **********Val Epoch 1: average Loss: 46.050608
2023-11-06 11:53: *********************************Current best model saved!
2023-11-06 11:53: Train Epoch 2: 0/158 Generator Loss: 43.866154 Pred Discriminator Loss: 0.569296 spatial Discriminator Loss: 0.483464 temporal Discriminator Loss: 0.872986
2023-11-06 11:53: Train Epoch 2: 20/158 Generator Loss: 35.179474 Pred Discriminator Loss: 0.614021 spatial Discriminator Loss: 0.529195 temporal Discriminator Loss: 0.740251
2023-11-06 11:53: Train Epoch 2: 40/158 Generator Loss: 33.151176 Pred Discriminator Loss: 0.599663 spatial Discriminator Loss: 0.518696 temporal Discriminator Loss: 0.778372
2023-11-06 11:54: Train Epoch 2: 60/158 Generator Loss: 29.819681 Pred Discriminator Loss: 0.611647 spatial Discriminator Loss: 0.551904 temporal Discriminator Loss: 0.731258
2023-11-06 11:54: Train Epoch 2: 80/158 Generator Loss: 28.479828 Pred Discriminator Loss: 0.597468 spatial Discriminator Loss: 0.565379 temporal Discriminator Loss: 0.548042
2023-11-06 11:54: Train Epoch 2: 100/158 Generator Loss: 27.052618 Pred Discriminator Loss: 0.616390 spatial Discriminator Loss: 0.585228 temporal Discriminator Loss: 0.726195
2023-11-06 11:54: Train Epoch 2: 120/158 Generator Loss: 29.803576 Pred Discriminator Loss: 0.595189 spatial Discriminator Loss: 0.571853 temporal Discriminator Loss: 0.673142
2023-11-06 11:54: Train Epoch 2: 140/158 Generator Loss: 27.781849 Pred Discriminator Loss: 0.613731 spatial Discriminator Loss: 0.600389 temporal Discriminator Loss: 0.721862
2023-11-06 11:54: **********Train Epoch 2: Averaged Generator Loss: 31.728144, Averaged Pred Discriminator Loss: 0.597222, Averaged spatial Discriminator Loss: 0.553022, Averaged temporal Discriminator Loss: 0.722342
2023-11-06 11:54: **********Val Epoch 2: average Loss: 25.175252
2023-11-06 11:54: *********************************Current best model saved!
2023-11-06 11:54: Train Epoch 3: 0/158 Generator Loss: 29.622902 Pred Discriminator Loss: 0.587777 spatial Discriminator Loss: 0.582959 temporal Discriminator Loss: 0.753378
2023-11-06 11:55: Train Epoch 3: 20/158 Generator Loss: 28.014618 Pred Discriminator Loss: 0.605844 spatial Discriminator Loss: 0.623491 temporal Discriminator Loss: 0.849001
2023-11-06 11:55: Train Epoch 3: 40/158 Generator Loss: 27.763712 Pred Discriminator Loss: 0.605378 spatial Discriminator Loss: 0.625511 temporal Discriminator Loss: 0.773821
2023-11-06 11:55: Train Epoch 3: 60/158 Generator Loss: 24.216249 Pred Discriminator Loss: 0.644162 spatial Discriminator Loss: 0.674887 temporal Discriminator Loss: 0.727838
2023-11-06 11:55: Train Epoch 3: 80/158 Generator Loss: 26.831236 Pred Discriminator Loss: 0.632968 spatial Discriminator Loss: 0.631134 temporal Discriminator Loss: 0.686098
2023-11-06 11:55: Train Epoch 3: 100/158 Generator Loss: 25.516041 Pred Discriminator Loss: 0.608178 spatial Discriminator Loss: 0.629166 temporal Discriminator Loss: 0.733108
2023-11-06 11:55: Train Epoch 3: 120/158 Generator Loss: 24.225925 Pred Discriminator Loss: 0.634620 spatial Discriminator Loss: 0.665369 temporal Discriminator Loss: 0.765759
2023-11-06 11:56: Train Epoch 3: 140/158 Generator Loss: 25.060175 Pred Discriminator Loss: 0.615238 spatial Discriminator Loss: 0.636260 temporal Discriminator Loss: 0.705934
2023-11-06 11:56: **********Train Epoch 3: Averaged Generator Loss: 25.356697, Averaged Pred Discriminator Loss: 0.624129, Averaged spatial Discriminator Loss: 0.644762, Averaged temporal Discriminator Loss: 0.729327
2023-11-06 11:56: **********Val Epoch 3: average Loss: 22.201417
2023-11-06 11:56: *********************************Current best model saved!
2023-11-06 11:56: Train Epoch 4: 0/158 Generator Loss: 25.644775 Pred Discriminator Loss: 0.626783 spatial Discriminator Loss: 0.654567 temporal Discriminator Loss: 0.729911
2023-11-06 11:56: Train Epoch 4: 20/158 Generator Loss: 22.593351 Pred Discriminator Loss: 0.642658 spatial Discriminator Loss: 0.660252 temporal Discriminator Loss: 0.726693
2023-11-06 11:56: Train Epoch 4: 40/158 Generator Loss: 23.965643 Pred Discriminator Loss: 0.632117 spatial Discriminator Loss: 0.672944 temporal Discriminator Loss: 0.702092
2023-11-06 11:56: Train Epoch 4: 60/158 Generator Loss: 24.974909 Pred Discriminator Loss: 0.634374 spatial Discriminator Loss: 0.676959 temporal Discriminator Loss: 0.669107
2023-11-06 11:56: Train Epoch 4: 80/158 Generator Loss: 23.356274 Pred Discriminator Loss: 0.618429 spatial Discriminator Loss: 0.662543 temporal Discriminator Loss: 0.726863
2023-11-06 11:57: Train Epoch 4: 100/158 Generator Loss: 24.386866 Pred Discriminator Loss: 0.620416 spatial Discriminator Loss: 0.677782 temporal Discriminator Loss: 0.722364
2023-11-06 11:57: Train Epoch 4: 120/158 Generator Loss: 24.005272 Pred Discriminator Loss: 0.641929 spatial Discriminator Loss: 0.660665 temporal Discriminator Loss: 0.696241
2023-11-06 11:57: Train Epoch 4: 140/158 Generator Loss: 24.602770 Pred Discriminator Loss: 0.625388 spatial Discriminator Loss: 0.663276 temporal Discriminator Loss: 0.682817
2023-11-06 11:57: **********Train Epoch 4: Averaged Generator Loss: 23.823423, Averaged Pred Discriminator Loss: 0.634510, Averaged spatial Discriminator Loss: 0.667365, Averaged temporal Discriminator Loss: 0.712514
2023-11-06 11:57: **********Val Epoch 4: average Loss: 21.153449
2023-11-06 11:57: *********************************Current best model saved!
2023-11-06 11:57: Train Epoch 5: 0/158 Generator Loss: 23.597330 Pred Discriminator Loss: 0.640237 spatial Discriminator Loss: 0.671781 temporal Discriminator Loss: 0.774337
2023-11-06 11:57: Train Epoch 5: 20/158 Generator Loss: 26.076801 Pred Discriminator Loss: 0.696456 spatial Discriminator Loss: 0.662563 temporal Discriminator Loss: 0.696567
2023-11-06 11:57: Train Epoch 5: 40/158 Generator Loss: 23.832684 Pred Discriminator Loss: 0.629558 spatial Discriminator Loss: 0.671014 temporal Discriminator Loss: 0.745058
2023-11-06 11:58: Train Epoch 5: 60/158 Generator Loss: 23.415279 Pred Discriminator Loss: 0.620810 spatial Discriminator Loss: 0.673904 temporal Discriminator Loss: 0.684374
2023-11-06 11:58: Train Epoch 5: 80/158 Generator Loss: 22.326855 Pred Discriminator Loss: 0.626024 spatial Discriminator Loss: 0.666448 temporal Discriminator Loss: 0.717475
2023-11-06 11:58: Train Epoch 5: 100/158 Generator Loss: 23.439503 Pred Discriminator Loss: 0.608996 spatial Discriminator Loss: 0.666586 temporal Discriminator Loss: 0.708247
2023-11-06 11:58: Train Epoch 5: 120/158 Generator Loss: 22.519108 Pred Discriminator Loss: 0.648065 spatial Discriminator Loss: 0.691174 temporal Discriminator Loss: 0.713701
2023-11-06 11:58: Train Epoch 5: 140/158 Generator Loss: 20.955770 Pred Discriminator Loss: 0.628443 spatial Discriminator Loss: 0.679802 temporal Discriminator Loss: 0.702019
2023-11-06 11:58: **********Train Epoch 5: Averaged Generator Loss: 22.955738, Averaged Pred Discriminator Loss: 0.636524, Averaged spatial Discriminator Loss: 0.676843, Averaged temporal Discriminator Loss: 0.716217
2023-11-06 11:58: **********Val Epoch 5: average Loss: 21.053853
2023-11-06 11:58: *********************************Current best model saved!
2023-11-06 11:58: Train Epoch 6: 0/158 Generator Loss: 23.371017 Pred Discriminator Loss: 0.619330 spatial Discriminator Loss: 0.694736 temporal Discriminator Loss: 0.726393
2023-11-06 11:59: Train Epoch 6: 20/158 Generator Loss: 22.437244 Pred Discriminator Loss: 0.619089 spatial Discriminator Loss: 0.682180 temporal Discriminator Loss: 0.701784
2023-11-06 11:59: Train Epoch 6: 40/158 Generator Loss: 22.498655 Pred Discriminator Loss: 0.614040 spatial Discriminator Loss: 0.673079 temporal Discriminator Loss: 0.688526
2023-11-06 11:59: Train Epoch 6: 60/158 Generator Loss: 22.216604 Pred Discriminator Loss: 0.654077 spatial Discriminator Loss: 0.692958 temporal Discriminator Loss: 0.703373
2023-11-06 11:59: Train Epoch 6: 80/158 Generator Loss: 21.317108 Pred Discriminator Loss: 0.624211 spatial Discriminator Loss: 0.683474 temporal Discriminator Loss: 0.706368
2023-11-06 11:59: Train Epoch 6: 100/158 Generator Loss: 23.109236 Pred Discriminator Loss: 0.625170 spatial Discriminator Loss: 0.691755 temporal Discriminator Loss: 0.706571
2023-11-06 11:59: Train Epoch 6: 120/158 Generator Loss: 22.816269 Pred Discriminator Loss: 0.615569 spatial Discriminator Loss: 0.689794 temporal Discriminator Loss: 0.717649
2023-11-06 11:59: Train Epoch 6: 140/158 Generator Loss: 21.265697 Pred Discriminator Loss: 0.631553 spatial Discriminator Loss: 0.685839 temporal Discriminator Loss: 0.685291
2023-11-06 12:00: **********Train Epoch 6: Averaged Generator Loss: 22.497420, Averaged Pred Discriminator Loss: 0.630275, Averaged spatial Discriminator Loss: 0.684787, Averaged temporal Discriminator Loss: 0.702012
2023-11-06 12:00: **********Val Epoch 6: average Loss: 20.145740
2023-11-06 12:00: *********************************Current best model saved!
2023-11-06 12:00: Train Epoch 7: 0/158 Generator Loss: 20.626076 Pred Discriminator Loss: 0.617817 spatial Discriminator Loss: 0.687154 temporal Discriminator Loss: 0.705258
2023-11-06 12:00: Train Epoch 7: 20/158 Generator Loss: 20.731581 Pred Discriminator Loss: 0.620730 spatial Discriminator Loss: 0.689166 temporal Discriminator Loss: 0.707915
2023-11-06 12:00: Train Epoch 7: 40/158 Generator Loss: 22.505655 Pred Discriminator Loss: 0.609402 spatial Discriminator Loss: 0.698142 temporal Discriminator Loss: 0.701957
2023-11-06 12:00: Train Epoch 7: 60/158 Generator Loss: 21.608107 Pred Discriminator Loss: 0.634067 spatial Discriminator Loss: 0.688423 temporal Discriminator Loss: 0.696237
2023-11-06 12:00: Train Epoch 7: 80/158 Generator Loss: 21.910019 Pred Discriminator Loss: 0.619109 spatial Discriminator Loss: 0.688251 temporal Discriminator Loss: 0.712316
2023-11-06 12:00: Train Epoch 7: 100/158 Generator Loss: 22.473444 Pred Discriminator Loss: 0.603035 spatial Discriminator Loss: 0.689321 temporal Discriminator Loss: 0.692495
2023-11-06 12:01: Train Epoch 7: 120/158 Generator Loss: 22.429428 Pred Discriminator Loss: 0.622099 spatial Discriminator Loss: 0.687630 temporal Discriminator Loss: 0.698073
2023-11-06 12:01: Train Epoch 7: 140/158 Generator Loss: 24.071827 Pred Discriminator Loss: 0.613099 spatial Discriminator Loss: 0.693131 temporal Discriminator Loss: 0.710501
2023-11-06 12:01: **********Train Epoch 7: Averaged Generator Loss: 22.072585, Averaged Pred Discriminator Loss: 0.624020, Averaged spatial Discriminator Loss: 0.688161, Averaged temporal Discriminator Loss: 0.701466
2023-11-06 12:01: **********Val Epoch 7: average Loss: 20.322184
2023-11-06 12:01: Train Epoch 8: 0/158 Generator Loss: 21.544416 Pred Discriminator Loss: 0.636288 spatial Discriminator Loss: 0.684398 temporal Discriminator Loss: 0.697739
