adaptive_embedding_dim: 8
batch_size: 64
dataset: PEMS04
debug: True
dim_embed_feature: 120
early_stop: True
early_stop_patience: 15
embed_dim: 6
epochs: 120
flow_dim: 1
gpu_id: 0
grad_norm: False
holiday_dim: 1
holiday_embedding_dim: 2
hop_dim: 1
in_steps: 12
input_dim: 5
input_embedding_dim: 80
log_dir: ./exps/logs/
log_step: 20
loss_func: mae
lr_decay: True
lr_decay_rate: 0.2
lr_decay_step: 80,100
lr_init: 0.006
mae_thresh: None
mape_thresh: 0.0
max_grad_norm: 5
mode: Train
model: MGSTGNN
normalizer: std
num_layers: 3
num_nodes: 307
out_steps: 12
output_dim: 1
period_dim: 1
periods: [288]
periods_embedding_dim: [24]
plot: False
real_value: True
rnn_units: 64
seed: 10
spatial_embedding_dim: 0
test_ratio: 0.2
val_ratio: 0.2
weather_dim: 0
weekend_dim: 1
weekend_embedding_dim: 6
*****************Model Parameter*****************
encoder.node_emb torch.Size([307, 0]) True
encoder.adaptive_embedding torch.Size([12, 307, 8]) True
encoder.input_proj.weight torch.Size([80, 5]) True
encoder.input_proj.bias torch.Size([80]) True
encoder.periods_embedding.0.weight torch.Size([288, 24]) True
encoder.weekend_embedding.weight torch.Size([2, 6]) True
encoder.holiday_embedding.weight torch.Size([2, 2]) True
encoder.output_proj.weight torch.Size([12, 1440]) True
encoder.output_proj.bias torch.Size([12]) True
encoder.skip.weight torch.Size([120, 5]) True
encoder.skip.bias torch.Size([120]) True
encoder.ln.weight torch.Size([120]) True
encoder.ln.bias torch.Size([120]) True
mgstgnn.encoder.node_embeddings torch.Size([307, 6]) True
mgstgnn.encoder.time_embeddings torch.Size([12, 6]) True
mgstgnn.encoder.gru0.gate_r.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.gru0.gate_z.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.gru0.update.weights_pool torch.Size([6, 2, 189, 64]) True
mgstgnn.encoder.gru0.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.gru0.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.gru0.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_r.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_z.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.0.update.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.0.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.0.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.0.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_r.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.gate_r.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.gate_r.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_r.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_z.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.gate_z.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.gate_z.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.gate_z.norm.bias torch.Size([6]) True
mgstgnn.encoder.grus.1.update.weights_pool torch.Size([6, 2, 128, 64]) True
mgstgnn.encoder.grus.1.update.bias_pool torch.Size([6, 64]) True
mgstgnn.encoder.grus.1.update.norm.weight torch.Size([6]) True
mgstgnn.encoder.grus.1.update.norm.bias torch.Size([6]) True
mgstgnn.encoder.gats.0.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.0.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.0.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.0.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.1.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.1.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.1.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.1.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.2.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.2.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.2.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.2.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.3.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.3.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.3.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.3.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.4.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.4.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.4.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.4.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.5.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.5.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.5.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.5.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.6.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.6.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.6.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.6.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.7.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.7.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.7.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.7.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.8.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.8.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.8.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.8.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.9.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.9.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.9.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.9.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.10.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.10.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.10.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.10.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.gats.11.output.fc1.weight torch.Size([256, 512]) True
mgstgnn.encoder.gats.11.output.fc1.bias torch.Size([256]) True
mgstgnn.encoder.gats.11.output.fc2.weight torch.Size([64, 256]) True
mgstgnn.encoder.gats.11.output.fc2.bias torch.Size([64]) True
mgstgnn.encoder.norms.0.weight torch.Size([64]) True
mgstgnn.encoder.norms.0.bias torch.Size([64]) True
mgstgnn.encoder.norms.1.weight torch.Size([64]) True
mgstgnn.encoder.norms.1.bias torch.Size([64]) True
mgstgnn.encoder.norms.2.weight torch.Size([64]) True
mgstgnn.encoder.norms.2.bias torch.Size([64]) True
mgstgnn.encoder.norms.3.weight torch.Size([64]) True
mgstgnn.encoder.norms.3.bias torch.Size([64]) True
mgstgnn.encoder.norms.4.weight torch.Size([64]) True
mgstgnn.encoder.norms.4.bias torch.Size([64]) True
mgstgnn.encoder.norms.5.weight torch.Size([64]) True
mgstgnn.encoder.norms.5.bias torch.Size([64]) True
mgstgnn.encoder.norms.6.weight torch.Size([64]) True
mgstgnn.encoder.norms.6.bias torch.Size([64]) True
mgstgnn.encoder.norms.7.weight torch.Size([64]) True
mgstgnn.encoder.norms.7.bias torch.Size([64]) True
mgstgnn.encoder.norms.8.weight torch.Size([64]) True
mgstgnn.encoder.norms.8.bias torch.Size([64]) True
mgstgnn.encoder.norms.9.weight torch.Size([64]) True
mgstgnn.encoder.norms.9.bias torch.Size([64]) True
mgstgnn.encoder.norms.10.weight torch.Size([64]) True
mgstgnn.encoder.norms.10.bias torch.Size([64]) True
mgstgnn.encoder.norms.11.weight torch.Size([64]) True
mgstgnn.encoder.norms.11.bias torch.Size([64]) True
mgstgnn.norm.weight torch.Size([64]) True
mgstgnn.norm.bias torch.Size([64]) True
mgstgnn.end_conv.weight torch.Size([12, 2, 1, 64]) True
mgstgnn.end_conv.bias torch.Size([12]) True
Total params num: 2862414
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 307]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 289281
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 307]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 289281
*****************Finish Parameter****************
*****************Model Parameter*****************
model.0.weight torch.Size([512, 12]) True
model.0.bias torch.Size([512]) True
model.2.weight torch.Size([256, 512]) True
model.2.bias torch.Size([256]) True
model.4.weight torch.Size([1, 256]) True
model.4.bias torch.Size([1]) True
Total params num: 138241
*****************Finish Parameter****************
(16992, 307, 5)
Train:  (10173, 12, 307, 5) (10173, 12, 307, 1)
Val:  (3375, 12, 307, 5) (3375, 12, 307, 1)
Test:  (3375, 12, 307, 5) (3375, 12, 307, 1)
Applying learning rate decay.
2023-11-06 11:48: Experiment log path in: /mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106114800
2023-11-06 11:48: Argument: Namespace(dataset='PEMS04', mode='Train', debug=True, model='MGSTGNN', gpu_id=0, val_ratio=0.2, test_ratio=0.2, in_steps=12, out_steps=12, num_nodes=307, normalizer='std', input_dim=5, flow_dim=1, period_dim=1, weekend_dim=1, holiday_dim=1, hop_dim=1, weather_dim=0, dim_embed_feature=120, input_embedding_dim=80, periods_embedding_dim=[24], weekend_embedding_dim=6, holiday_embedding_dim=2, spatial_embedding_dim=0, adaptive_embedding_dim=8, output_dim=1, embed_dim=6, rnn_units=64, num_layers=3, periods=[288], loss_func='mae', seed=10, batch_size=64, epochs=120, lr_init=0.006, lr_decay=True, lr_decay_rate=0.2, lr_decay_step='80,100', early_stop=True, early_stop_patience=15, grad_norm=False, max_grad_norm=5, real_value=True, mae_thresh=None, mape_thresh=0.0, log_dir='/mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106114800', log_step=20, plot=False, device=device(type='cuda', index=0))
2023-11-06 11:48: adaptive_embedding_dim: 8
2023-11-06 11:48: batch_size: 64
2023-11-06 11:48: dataset: PEMS04
2023-11-06 11:48: debug: True
2023-11-06 11:48: device: cuda:0
2023-11-06 11:48: dim_embed_feature: 120
2023-11-06 11:48: early_stop: True
2023-11-06 11:48: early_stop_patience: 15
2023-11-06 11:48: embed_dim: 6
2023-11-06 11:48: epochs: 120
2023-11-06 11:48: flow_dim: 1
2023-11-06 11:48: gpu_id: 0
2023-11-06 11:48: grad_norm: False
2023-11-06 11:48: holiday_dim: 1
2023-11-06 11:48: holiday_embedding_dim: 2
2023-11-06 11:48: hop_dim: 1
2023-11-06 11:48: in_steps: 12
2023-11-06 11:48: input_dim: 5
2023-11-06 11:48: input_embedding_dim: 80
2023-11-06 11:48: log_dir: /mnt/workspace/MGSTGNN/exps/logs/PEMS04/20231106114800
2023-11-06 11:48: log_step: 20
2023-11-06 11:48: loss_func: mae
2023-11-06 11:48: lr_decay: True
2023-11-06 11:48: lr_decay_rate: 0.2
2023-11-06 11:48: lr_decay_step: 80,100
2023-11-06 11:48: lr_init: 0.006
2023-11-06 11:48: mae_thresh: None
2023-11-06 11:48: mape_thresh: 0.0
2023-11-06 11:48: max_grad_norm: 5
2023-11-06 11:48: mode: Train
2023-11-06 11:48: model: MGSTGNN
2023-11-06 11:48: normalizer: std
2023-11-06 11:48: num_layers: 3
2023-11-06 11:48: num_nodes: 307
2023-11-06 11:48: out_steps: 12
2023-11-06 11:48: output_dim: 1
2023-11-06 11:48: period_dim: 1
2023-11-06 11:48: periods: [288]
2023-11-06 11:48: periods_embedding_dim: [24]
2023-11-06 11:48: plot: False
2023-11-06 11:48: real_value: True
2023-11-06 11:48: rnn_units: 64
2023-11-06 11:48: seed: 10
2023-11-06 11:48: spatial_embedding_dim: 0
2023-11-06 11:48: test_ratio: 0.2
2023-11-06 11:48: val_ratio: 0.2
2023-11-06 11:48: weather_dim: 0
2023-11-06 11:48: weekend_dim: 1
2023-11-06 11:48: weekend_embedding_dim: 6
2023-11-06 11:48: Train Epoch 1: 0/158 Generator Loss: 213.210739 Pred Discriminator Loss: 1.091009 spatial Discriminator Loss: 0.761716 temporal Discriminator Loss: 0.832835
